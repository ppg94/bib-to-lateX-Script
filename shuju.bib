@article{porpiglia2020three,
  title={Three-dimensional augmented reality robot-assisted partial nephrectomy in case of complex tumours (PADUA≥ 10): a new intraoperative tool overcoming the ultrasound guidance},
  author={Porpiglia, Francesco and Checcucci, Enrico and Amparore, Daniele and Piramide, Federico and Volpi, Gabriele and Granato, Stefano and Verri, Paolo and Manfredi, Matteo and Bellin, Andrea and Piazzolla, Pietro and others},
  journal={European urology},
  volume={78},
  number={2},
  pages={229--238},
  year={2020},
  publisher={Elsevier}
}

@article{reinschluessel2022virtual,
  title={Virtual reality for surgical planning--evaluation based on two liver tumor resections},
  author={Reinschluessel, Anke V and Muender, Thomas and Salzmann, Daniela and Doering, Tanja and Malaka, Rainer and Weyhe, Dirk},
  journal={Frontiers in Surgery},
  volume={9},
  pages={821060},
  year={2022},
  publisher={Frontiers Media SA}
}
@inproceedings{xu2022self,
  title={Self-supervised multi-view stereo via adjacent geometry guided volume completion},
  author={Xu, Luoyuan and Guan, Tao and Wang, Yuesong and Luo, Yawei and Chen, Zhuo and Liu, Wenkai and Yang, Wei},
  booktitle={Proceedings of the 30th acm international conference on multimedia},
  pages={2202--2210},
  year={2022}
}
@inproceedings{hamdi2021mvtn,
  title={Mvtn: Multi-view transformation network for 3d shape recognition},
  author={Hamdi, Abdullah and Giancola, Silvio and Ghanem, Bernard},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1--11},
  year={2021}
}
@article{WANG2024105600,
title = {Enhancing 3D reconstruction of textureless indoor scenes with IndoReal multi-view stereo (MVS)},
journal = {Automation in Construction},
volume = {166},
pages = {105600},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105600},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524003364},
author = {Tao Wang and Vincent J.L. Gan},
keywords = {Indoor MVS dataset, Unsupervised learning, Indoor 3D reconstruction, Geometric digital twinning, Textureless reconstruction, 3D computer vision},
abstract = {3D reconstruction plays a pivotal role in capturing the built environment's object shapes and appearances for diverse smart applications, such as indoor navigation and geometric digital twinning. Despite its significance, traditional Multi-View Stereo (MVS) techniques are ineffective in indoor environments, characterised by textureless walls, illumination variation, and other nuanced phenomena. Moreover, current learning-based MVS pipelines are often developed without considering indoor attributes and rely on costly ground truth data for performance optimisation. This paper presents the “IndoReal-MVS” dataset, a rich indoor-centric compilation reflecting real-world phenomena through advanced computer graphics. It also introduces unsupervised “IndoorMatchNet”, synergising Feature Pyramid Network (FPN) and Pyramid Flowformer (PFF) for encoding complex indoor geometries. The pipeline proposes Multi-Scale Feature loss, Superpixel-based Normal Consistency and Depth Smoothness losses, designed for indoor geometric characteristics. Experiments showcase a 192% relative improvement over the baseline model at stringent error thresholds, advancing indoor 3D reconstruction tasks.}
}
@ARTICLE{9484777,
  author={Kong, Da and Zhang, Yu and Dai, Weichen},
  journal={IEEE Robotics and Automation Letters}, 
  title={Direct Near-Infrared-Depth Visual SLAM With Active Lighting}, 
  year={2021},
  volume={6},
  number={4},
  pages={7057-7064},
  keywords={Cameras;Lighting;Simultaneous localization and mapping;Visualization;Light sources;Robot vision systems;Pose estimation;Localization;SLAM},
  doi={10.1109/LRA.2021.3096741}}
@inproceedings{pan2024harmonicnerf,
  title={HarmonicNeRF: Geometry-informed synthetic view augmentation for 3D scene reconstruction in driving scenarios},
  author={Pan, Xiaochao and Yao, Jiawei and Kou, Hongrui and Wu, Tong and Xiao, Canran},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={5987--5996},
  year={2024}
}
@inproceedings{10.1145/3588432.3591483,
author = {Wu, Tong and Sun, Jia-Mu and Lai, Yu-Kun and Gao, Lin},
title = {DE-NeRF: DEcoupled Neural Radiance Fields for View-Consistent Appearance Editing and High-Frequency Environmental Relighting},
year = {2023},
isbn = {9798400701597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3588432.3591483},
doi = {10.1145/3588432.3591483},
abstract = {Neural Radiance Fields (NeRF) have shown promising results in novel view synthesis. While achieving state-of-the-art rendering results, NeRF usually encodes all properties related to geometry and appearance of the scene together into several MLP (Multi-Layer Perceptron) networks, which hinders downstream manipulation of geometry, appearance and illumination. Recently researchers made attempts to edit geometry, appearance and lighting for NeRF. However, they fail to render view-consistent results after editing the appearance of the input scene. Moreover, high-frequency environmental relighting is also beyond their capability as lighting is modeled as Spherical Gaussian (SG) and Spherical Harmonic (SH) functions or a low-resolution environment map. To solve the above problems, we propose DE-NeRF to decouple view-independent appearance and view-dependent appearance in the scene with a hybrid lighting representation. Specifically, we first train a signed distance function to reconstruct an explicit mesh for the input scene. Then a decoupled NeRF learns to attach view-independent appearance to the reconstructed mesh by defining learnable disentangled features representing geometry and view-independent appearance on its vertices. For lighting, we approximate it with an explicit learnable environment map and an implicit lighting network to support both low-frequency and high-frequency relighting. By modifying the view-independent appearance, rendered results are consistent across different viewpoints. Our method also supports high-frequency environmental relighting by replacing the explicit environment map with a novel one and fitting the implicit lighting network to the novel environment map. Experiments show that our method achieves better editing and relighting performance both quantitatively and qualitatively compared to previous methods.},
booktitle = {ACM SIGGRAPH 2023 Conference Proceedings},
articleno = {74},
numpages = {11},
keywords = {editing, inverse rendering, neural radiance fields},
location = {Los Angeles, CA, USA},
series = {SIGGRAPH '23}
}
@inproceedings{gao2024relightable,
  title={Relightable 3d gaussians: Realistic point cloud relighting with brdf decomposition and ray tracing},
  author={Gao, Jian and Gu, Chun and Lin, Youtian and Li, Zhihao and Zhu, Hao and Cao, Xun and Zhang, Li and Yao, Yao},
  booktitle={European Conference on Computer Vision},
  pages={73--89},
  year={2024},
  organization={Springer}
}
@article{reiser2024binary,
  title={Binary opacity grids: Capturing fine geometric detail for mesh-based view synthesis},
  author={Reiser, Christian and Garbin, Stephan and Srinivasan, Pratul and Verbin, Dor and Szeliski, Richard and Mildenhall, Ben and Barron, Jonathan and Hedman, Peter and Geiger, Andreas},
  journal={ACM Transactions on Graphics (TOG)},
  volume={43},
  number={4},
  pages={1--14},
  year={2024},
  publisher={ACM New York, NY, USA}
}
@inproceedings{gao2024relightable,
  title={Relightable 3d gaussians: Realistic point cloud relighting with brdf decomposition and ray tracing},
  author={Gao, Jian and Gu, Chun and Lin, Youtian and Li, Zhihao and Zhu, Hao and Cao, Xun and Zhang, Li and Yao, Yao},
  booktitle={European Conference on Computer Vision},
  pages={73--89},
  year={2024},
  organization={Springer}
}
@inproceedings{li2023neuralangelo,
  title={Neuralangelo: High-fidelity neural surface reconstruction},
  author={Li, Zhaoshuo and M{\"u}ller, Thomas and Evans, Alex and Taylor, Russell H and Unberath, Mathias and Liu, Ming-Yu and Lin, Chen-Hsuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8456--8465},
  year={2023}
}
@inproceedings{niemeyer2022regnerf,
  title={Regnerf: Regularizing neural radiance fields for view synthesis from sparse inputs},
  author={Niemeyer, Michael and Barron, Jonathan T and Mildenhall, Ben and Sajjadi, Mehdi SM and Geiger, Andreas and Radwan, Noha},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5480--5490},
  year={2022}
}
@inproceedings{yang2023freenerf,
  title={Freenerf: Improving few-shot neural rendering with free frequency regularization},
  author={Yang, Jiawei and Pavone, Marco and Wang, Yue},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8254--8263},
  year={2023}
}
@article{chen2024vcr,
  title={Vcr-gaus: View consistent depth-normal regularizer for gaussian surface reconstruction},
  author={Chen, Hanlin and Wei, Fangyin and Li, Chen and Huang, Tianxin and Wang, Yunsong and Lee, Gim Hee},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={139725--139750},
  year={2024}
}
@article{yariv2020multiview,
  title={Multiview neural surface reconstruction by disentangling geometry and appearance},
  author={Yariv, Lior and Kasten, Yoni and Moran, Dror and Galun, Meirav and Atzmon, Matan and Ronen, Basri and Lipman, Yaron},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2492--2502},
  year={2020}
}
@inproceedings{azinovic2022neural,
  title={Neural rgb-d surface reconstruction},
  author={Azinovi{\'c}, Dejan and Martin-Brualla, Ricardo and Goldman, Dan B and Nie{\ss}ner, Matthias and Thies, Justus},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6290--6301},
  year={2022}
}
@inproceedings{wang2021neus,
  title={NeuS: learning neural implicit surfaces by volume rendering for multi-view reconstruction},
  author={Wang, Peng and Liu, Lingjie and Liu, Yuan and Theobalt, Christian and Komura, Taku and Wang, Wenping},
  booktitle={Proceedings of the 35th International Conference on Neural Information Processing Systems},
  pages={27171--27183},
  year={2021}
}
@article{li2024tensosdf,
  title={Tensosdf: Roughness-aware tensorial representation for robust geometry and material reconstruction},
  author={Li, Jia and Wang, Lu and Zhang, Lei and Wang, Beibei},
  journal={ACM Transactions on Graphics (TOG)},
  volume={43},
  number={4},
  pages={1--13},
  year={2024},
  publisher={ACM New York, NY, USA}
}
@inproceedings{zha2023endosurf,
  title={Endosurf: Neural surface reconstruction of deformable tissues with stereo endoscope videos},
  author={Zha, Ruyi and Cheng, Xuelian and Li, Hongdong and Harandi, Mehrtash and Ge, Zongyuan},
  booktitle={International conference on medical image computing and computer-assisted intervention},
  pages={13--23},
  year={2023},
  organization={Springer}
}
@article{xu2024gsurf,
  title={GSurf: 3D Reconstruction via Signed Distance Fields with Direct Gaussian Supervision},
  author={Xu, Baixin and Hu, Jiangbei and Li, Jiaze and He, Ying},
  journal={arXiv preprint arXiv:2411.15723},
  year={2024}
}
@inproceedings{huang20242d,
  title={2d gaussian splatting for geometrically accurate radiance fields},
  author={Huang, Binbin and Yu, Zehao and Chen, Anpei and Geiger, Andreas and Gao, Shenghua},
  booktitle={ACM SIGGRAPH 2024 conference papers},
  pages={1--11},
  year={2024}
}
@inproceedings{huang2023neural,
  title={Neural kernel surface reconstruction},
  author={Huang, Jiahui and Gojcic, Zan and Atzmon, Matan and Litany, Or and Fidler, Sanja and Williams, Francis},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4369--4379},
  year={2023}
}
@article{yariv2020multiview,
  title={Multiview neural surface reconstruction by disentangling geometry and appearance},
  author={Yariv, Lior and Kasten, Yoni and Moran, Dror and Galun, Meirav and Atzmon, Matan and Ronen, Basri and Lipman, Yaron},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2492--2502},
  year={2020}
}
@article{nimier2019mitsuba,
  title={Mitsuba 2: A retargetable forward and inverse renderer},
  author={Nimier-David, Merlin and Vicini, Delio and Zeltner, Tizian and Jakob, Wenzel},
  journal={ACM Transactions on Graphics (ToG)},
  volume={38},
  number={6},
  pages={1--17},
  year={2019},
  publisher={ACM New York, NY, USA}
}
@article{garces2022survey,
  title={A survey on intrinsic images: Delving deep into lambert and beyond},
  author={Garces, Elena and Rodriguez-Pardo, Carlos and Casas, Dan and Lopez-Moreno, Jorge},
  journal={International Journal of Computer Vision},
  volume={130},
  number={3},
  pages={836--868},
  year={2022},
  publisher={Springer}
}
@article{mildenhall2021nerf,
  title={Nerf: Representing scenes as neural radiance fields for view synthesis},
  author={Mildenhall, Ben and Srinivasan, Pratul P and Tancik, Matthew and Barron, Jonathan T and Ramamoorthi, Ravi and Ng, Ren},
  journal={Communications of the ACM},
  volume={65},
  number={1},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@article{kerbl20233d,
  title={3d gaussian splatting for real-time radiance field rendering.},
  author={Kerbl, Bernhard and Kopanas, Georgios and Leimk{\"u}hler, Thomas and Drettakis, George},
  journal={ACM Trans. Graph.},
  volume={42},
  number={4},
  pages={139--1},
  year={2023}
}
@inproceedings{verbin2022ref,
  title={Ref-nerf: Structured view-dependent appearance for neural radiance fields},
  author={Verbin, Dor and Hedman, Peter and Mildenhall, Ben and Zickler, Todd and Barron, Jonathan T and Srinivasan, Pratul P},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={5481--5490},
  year={2022},
  organization={IEEE}
}
@inproceedings{yao2022neilf,
  title={Neilf: Neural incident light field for physically-based material estimation},
  author={Yao, Yao and Zhang, Jingyang and Liu, Jingbo and Qu, Yihang and Fang, Tian and McKinnon, David and Tsin, Yanghai and Quan, Long},
  booktitle={European conference on computer vision},
  pages={700--716},
  year={2022},
  organization={Springer}
}
@article{liu2023nero,
  title={Nero: Neural geometry and brdf reconstruction of reflective objects from multiview images},
  author={Liu, Yuan and Wang, Peng and Lin, Cheng and Long, Xiaoxiao and Wang, Jiepeng and Liu, Lingjie and Komura, Taku and Wang, Wenping},
  journal={ACM Transactions on Graphics (ToG)},
  volume={42},
  number={4},
  pages={1--22},
  year={2023},
  publisher={ACM New York, NY, USA}
}
@article{ye2024geosplatting,
  title={GeoSplatting: Towards Geometry Guided Gaussian Splatting for Physically-based Inverse Rendering},
  author={Ye, Kai and Gao, Chong and Li, Guanbin and Chen, Wenzheng and Chen, Baoquan},
  journal={arXiv preprint arXiv:2410.24204},
  year={2024}
}
@inproceedings{ye20243d,
  title={3d gaussian splatting with deferred reflection},
  author={Ye, Keyang and Hou, Qiming and Zhou, Kun},
  booktitle={ACM SIGGRAPH 2024 Conference Papers},
  pages={1--10},
  year={2024}
}
@article{yang2024spec,
  title={Spec-gaussian: Anisotropic view-dependent appearance for 3d gaussian splatting},
  author={Yang, Ziyi and Gao, Xinyu and Sun, Yang-Tian and Huang, Yihua and Lyu, Xiaoyang and Zhou, Wen and Jiao, Shaohui and Qi, Xiaojuan and Jin, Xiaogang},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={61192--61216},
  year={2024}
}
@inproceedings{liu2024mirrorgaussian,
  title={Mirrorgaussian: Reflecting 3d gaussians for reconstructing mirror reflections},
  author={Liu, Jiayue and Tang, Xiao and Cheng, Freeman and Yang, Roy and Li, Zhihao and Liu, Jianzhuang and Huang, Yi and Lin, Jiaqi and Liu, Shiyong and Wu, Xiaofei and others},
  booktitle={European Conference on Computer Vision},
  pages={377--393},
  year={2024},
  organization={Springer}
}
@inproceedings{jiang2024gaussianshader,
  title={Gaussianshader: 3d gaussian splatting with shading functions for reflective surfaces},
  author={Jiang, Yingwenqi and Tu, Jiadong and Liu, Yuan and Gao, Xifeng and Long, Xiaoxiao and Wang, Wenping and Ma, Yuexin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5322--5332},
  year={2024}
}
@article{shi2023gir,
  title={Gir: 3d gaussian inverse rendering for relightable scene factorization},
  author={Shi, Yahao and Wu, Yanmin and Wu, Chenming and Liu, Xing and Zhao, Chen and Feng, Haocheng and Zhang, Jian and Zhou, Bin and Ding, Errui and Wang, Jingdong},
  journal={arXiv preprint arXiv:2312.05133},
  year={2023}
}
@article{wu2024gani,
  title={GaNI: Global and Near Field Illumination Aware Neural Inverse Rendering},
  author={Wu, Jiaye and Hadadan, Saeed and Lin, Geng and Zwicker, Matthias and Jacobs, David and Sengupta, Roni},
  journal={arXiv preprint arXiv:2403.15651},
  year={2024}
}
@article{fan2024spectromotion,
  title={SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes},
  author={Fan, Cheng-De and Chang, Chen-Wei and Liu, Yi-Ruei and Lee, Jie-Ying and Huang, Jiun-Long and Tseng, Yu-Chee and Liu, Yu-Lun},
  journal={arXiv preprint arXiv:2410.17249},
  year={2024}
}